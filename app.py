# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pCHjj_0mkqh3D2Eto8HLlXFhY-EXurtd
"""

# ğŸ“¦ ì„¤ì¹˜ í•„ìš”: streamlit, feedparser, keybert, sentence-transformers
# pip install streamlit feedparser keybert sentence-transformers
# -*- coding: utf-8 -*-
import streamlit as st
import feedparser
from keybert import KeyBERT
from collections import Counter

st.title("ê²€ìƒ‰ í‚¤ì›Œë“œ ìë™ ì¶”ì¶œê¸°ğŸ”")
st.write("Google ë‰´ìŠ¤ ê¸°ì‚¬ ê¸°ë°˜ìœ¼ë¡œ ì…ë ¥í•œ í‚¤ì›Œë“œ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ê³ , ìì£¼ ë“±ì¥í•˜ëŠ” í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")

query = st.text_input("ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥ (ì˜ˆ: miami, sunscreen, summer)", "miami")

if st.button("ğŸš€ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œì‘"):
    with st.spinner("ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ì§‘ ì¤‘..."):
        rss_url = f"https://news.google.com/rss/search?q={query}&hl=en-US&gl=US&ceid=US:en"
        feed = feedparser.parse(rss_url)
        articles = [entry.title + ". " + entry.get("summary", "") for entry in feed.entries]

    if not articles:
        st.warning("ê´€ë ¨ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
    else:
        st.success(f"ì´ ìˆ˜ì§‘ ê¸°ì‚¬ ìˆ˜: {len(articles)}ê°œ")

        with st.spinner("í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘..."):
            kw_model = KeyBERT()
            keywords = []
            for article in articles:
                try:
                    kws = kw_model.extract_keywords(article, keyphrase_ngram_range=(1, 2), stop_words="english", top_n=3)
                    keywords.extend([kw[0] for kw in kws])
                except:
                    continue

            counts = Counter(keywords)
            top_keywords = counts.most_common(30)

        st.subheader("ğŸ“ˆ ìƒìœ„ í‚¤ì›Œë“œ 30ê°œ")
        for word, count in top_keywords:
            st.write(f"{word} ({count}íšŒ)")

