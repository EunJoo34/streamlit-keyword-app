# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pCHjj_0mkqh3D2Eto8HLlXFhY-EXurtd
"""

# 📦 설치 필요: streamlit, feedparser, keybert, sentence-transformers
# pip install streamlit feedparser keybert sentence-transformers
# -*- coding: utf-8 -*-
import streamlit as st
import feedparser
from keybert import KeyBERT
from collections import Counter

st.title("검색 키워드 자동 추출기🔍")
st.write("Google 뉴스 기사 기반으로 입력한 키워드 관련 뉴스를 분석하고, 자주 등장하는 핵심 키워드를 추출합니다.")

query = st.text_input("🔍 검색 키워드 입력 (예: miami, sunscreen, summer)", "miami")

if st.button("🚀 키워드 추출 시작"):
    with st.spinner("뉴스 기사 수집 중..."):
        rss_url = f"https://news.google.com/rss/search?q={query}&hl=en-US&gl=US&ceid=US:en"
        feed = feedparser.parse(rss_url)
        articles = [entry.title + ". " + entry.get("summary", "") for entry in feed.entries]

    if not articles:
        st.warning("관련 기사를 찾을 수 없습니다. 다른 키워드를 시도해보세요.")
    else:
        st.success(f"총 수집 기사 수: {len(articles)}개")

        with st.spinner("키워드 추출 중..."):
            kw_model = KeyBERT()
            keywords = []
            for article in articles:
                try:
                    kws = kw_model.extract_keywords(article, keyphrase_ngram_range=(1, 2), stop_words="english", top_n=3)
                    keywords.extend([kw[0] for kw in kws])
                except:
                    continue

            counts = Counter(keywords)
            top_keywords = counts.most_common(30)

        st.subheader("📈 상위 키워드 30개")
        for word, count in top_keywords:
            st.write(f"{word} ({count}회)")

